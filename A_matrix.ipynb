{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set auto reload for python functions\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import packages\n",
    "import glob\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from M_matrix import _parse_function\n",
    "from M_matrix import gen_reduce_max_tensors\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "# GoogLeNet # Need to install lucid with the command: `pip install lucid`\n",
    "import lucid.modelzoo.vision_models as models\n",
    "import lucid.optvis.render as render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer info\n",
    "layer_sizes = {\n",
    "    'mixed3a': 256,\n",
    "    'mixed3b': 480,\n",
    "    'mixed4a': 508,\n",
    "    'mixed4b': 512,\n",
    "    'mixed4c': 512,\n",
    "    'mixed4d': 528,\n",
    "    'mixed4e': 832,\n",
    "    'mixed5a': 832,\n",
    "    'mixed5b': 1024\n",
    "}\n",
    "layers = list(layer_sizes.keys())\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "num_of_classes = 1000\n",
    "prob_mass_threshold = 0.1\n",
    "batch = 200\n",
    "\n",
    "# Input directory path\n",
    "input_dir_path = '/Users/haekyu/data/imagenet-tf-records'\n",
    "\n",
    "# Output directory path\n",
    "output_dir_path = '/Users/haekyu/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import googlenet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet = models.InceptionV1()\n",
    "googlenet.load_graphdef()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get A-matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize A-matrices\n",
    "\n",
    "(Still editing, copy and paste summit paper, section 6.1) We want to understand what a neural network is detecting in a dataset. We propose summarizing how an image dataset is represented through-out a CNN by aggregating individual image activations at each channel in the network, over all of the images in a given class. This aggregation results in a matrix, Al for each layer l in a network, where an entry Al cj roughly represents how important channel j (from the lth layer) is for representing images from class c.\n",
    "\n",
    "We define As to keep the aggregation result.\n",
    "```\n",
    "As: a dictionary, where\n",
    "    - key: layer name in string (e.g., \"mixed3a\")\n",
    "    - val: a matrix (np.array(dtype=int)) of shape (#class, #channels)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "As = {}\n",
    "for layer in layer_sizes:\n",
    "    num_of_channels_in_layer = layer_sizes[layer]\n",
    "    A = np.zeros([num_of_classes, num_of_channels_in_layer], dtype=int)\n",
    "    As[layer] = A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate the activation and complete A-matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time checker\n",
    "start_time = time()\n",
    "\n",
    "# Get file paths\n",
    "file_paths = glob.glob('{}/*'.format(input_dir_path))\n",
    "\n",
    "# Get A-matrix\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    # Define parsed dataset tensor\n",
    "    dataset = tf.data.TFRecordDataset(file_paths)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    dataset = dataset.map(lambda img, lab, syn: (preprocess_input(img), lab, syn))\n",
    "    dataset = dataset.batch(batch)\n",
    "\n",
    "    # Define iterator through the datasets\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    t_preprocessed_images, t_labels, t_synsets = iterator.get_next()\n",
    "    \n",
    "    # Define actiavtion map render\n",
    "    T = render.import_model(googlenet, t_preprocessed_images, None)\n",
    "    t_act_max_all_layers = gen_reduce_max_tensors(layers, T)\n",
    "    \n",
    "    # Read data\n",
    "    progress_counter, image_id = 0, -1\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        tic = time()\n",
    "\n",
    "        try:\n",
    "            with tqdm.tqdm(total=1243025, unit='imgs') as pbar:\n",
    "                while(True):\n",
    "                    \n",
    "                    # Get parsed data\n",
    "                    progress_counter += 1\n",
    "                    act_maxs_3a, act_maxs_3b, act_maxs_4a, act_maxs_4b, \\\n",
    "                    act_maxs_4c, act_maxs_4d, act_maxs_4e, act_maxs_5a, \\\n",
    "                    act_maxs_5b, labels, synsets = \\\n",
    "                        sess.run([*t_act_max_all_layers, t_labels, t_synsets])\n",
    "                    \n",
    "                    '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "                    no sess.run after this!\n",
    "                    python code here on out\n",
    "                    '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "                    \n",
    "                    # Define a list for activation maximums of all layers\n",
    "                    act_maxs_all_layers = {\n",
    "                        'mixed3a': act_maxs_3a,\n",
    "                        'mixed3b': act_maxs_3b,\n",
    "                        'mixed4a': act_maxs_4a,\n",
    "                        'mixed4b': act_maxs_4b,\n",
    "                        'mixed4c': act_maxs_4c,\n",
    "                        'mixed4d': act_maxs_4d,\n",
    "                        'mixed4e': act_maxs_4e,\n",
    "                        'mixed5a': act_maxs_5a,\n",
    "                        'mixed5b': act_maxs_5b\n",
    "                    }\n",
    "                    \n",
    "                    # Get the current batch size.\n",
    "                    # It could be smaller than batch in tail\n",
    "                    curr_batch_size = labels.shape[0] \n",
    "                    \n",
    "                    # For an image i\n",
    "                    for i in range(curr_batch_size):\n",
    "                        \n",
    "                        # Image id\n",
    "                        image_id += 1\n",
    "                        \n",
    "                        # Initialize the co-activated neurons info\n",
    "                        co_activated_neurons[image_id] = {'label': labels[i] - 1}\n",
    "\n",
    "                        # For each layer's activation maximums\n",
    "                        for layer in layers:\n",
    "                            \n",
    "                            # Get activation map of an image\n",
    "                            act_max = act_maxs_all_layers[layer][i]\n",
    "\n",
    "                            # Remove outlier / non-semantic channels\n",
    "                            # Set their activation maximum as 0, \n",
    "                            # so that they can be ignored later\n",
    "                            if layer == 'mixed3a':\n",
    "                                act_max[67] = 0\n",
    "                                act_max[190] = 0\n",
    "\n",
    "                            if layer == 'mixed3b':\n",
    "                                act_max[390] = 0\n",
    "                                act_max[399] = 0\n",
    "                                act_max[412] = 0\n",
    "\n",
    "                            # Sort the neurons by the activation strength\n",
    "                            normalized_act_max = act_max / np.sum(act_max)\n",
    "                            sorted_normalized_act_max, sorted_idxs = (list(t) for t in \n",
    "                                zip(*sorted(zip(normalized_act_max, list(range(normalized_act_max.shape[0]))), reverse=True)))\n",
    "\n",
    "                            # Get highly activated neurons\n",
    "                            prob_mass, k = 0, 0\n",
    "                            while prob_mass < prob_mass_threshold:\n",
    "                                prob_mass += sorted_normalized_act_max[k]\n",
    "                                k += 1\n",
    "                            top_neurons = sorted_idxs[:k]\n",
    "\n",
    "                            # Add the top neurons into the result\n",
    "                            for top_neuron in top_neurons:\n",
    "                                As[layer][labels[i] - 1][top_neuron] += 1\n",
    "\n",
    "                        pbar.update(len(labels))\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "\n",
    "# Time checker\n",
    "end_time = time()\n",
    "print('Total time: %.2lf sec' % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save A-matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in layer_sizes:\n",
    "    output_filepath = '{}/A-{}-{}.csv'.format(output_dir_path, prob_mass_threshold, layer)\n",
    "    np.savetxt(output_filepath, A, delimiter=',', fmt='%i')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
