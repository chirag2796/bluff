{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set auto reload for python functions\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import packages\n",
    "import os\n",
    "from time import time\n",
    "from I_matrix import get_channel_sizes\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "# GoogLeNet # Need to install lucid with the command: `pip install lucid`\n",
    "import lucid.modelzoo.vision_models as models\n",
    "import lucid.optvis.render as render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU to use\n",
    "use_gpu = False\n",
    "gpu = 0\n",
    "\n",
    "# Input directory path\n",
    "input_dir_path = '/Users/haekyu/data/imagenet-tf-records'\n",
    "\n",
    "# Output directory path\n",
    "output_dir_path = '/Users/haekyu/data/massif/I-mat'\n",
    "\n",
    "# Layer info\n",
    "layer_sizes = {\n",
    "    'mixed3a': 256,\n",
    "    'mixed3b': 480,\n",
    "    'mixed4a': 508,\n",
    "    'mixed4b': 512,\n",
    "    'mixed4c': 512,\n",
    "    'mixed4d': 528,\n",
    "    'mixed4e': 832,\n",
    "    'mixed5a': 832,\n",
    "    'mixed5b': 1024\n",
    "}\n",
    "layers = list(layer_sizes.keys())\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "# Pick a layer\n",
    "layer = 'mixed3a'\n",
    "\n",
    "# Class info\n",
    "num_class = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a GPU\n",
    "if use_gpu:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet = models.InceptionV1()\n",
    "googlenet.load_graphdef()\n",
    "nodes = googlenet.graph_def.node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_layers = [layer for layer in layers if 'mixed' in layer]\n",
    "layer_fragment_sizes = {layer: get_channel_sizes(layer, nodes) for layer in mixed_layers}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get I-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_I_matrix(layer, all_layers, input_dir_path):\n",
    "    \n",
    "    # Get previous layer\n",
    "    prev_layer = get_prev_layer(all_layers, layer)\n",
    "\n",
    "    # Time checker\n",
    "    start_time = time()\n",
    "\n",
    "    # Get file paths\n",
    "    # file_paths = glob.glob('{}/*'.format(input_dir_path))\n",
    "    file_paths = glob.glob('{}/train-00000-of-01024'.format(input_dir_path))\n",
    "\n",
    "    # Get I-matrix\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        # Define parsed dataset tensor\n",
    "        dataset = tf.data.TFRecordDataset(filenames)\n",
    "        dataset = dataset.map(_parse_function)\n",
    "        dataset = dataset.map(lambda img, lab, syn: (preprocess_input(img), lab, syn))\n",
    "        dataset = dataset.batch(batch)\n",
    "\n",
    "        # Define iterator through the datasets\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        t_preprocessed_images, t_labels, t_synsets = iterator.get_next()\n",
    "\n",
    "        # Define actiavtion map render\n",
    "        T = render.import_model(googlenet, t_preprocessed_images, None)\n",
    "\n",
    "        # Get weight tensors\n",
    "        t_w0, t_w1, t_w2, t_w3, t_w4, t_w5 = get_weight_tensors(mixed_layer)\n",
    "\n",
    "        # Get intermediate layer tensors\n",
    "        t_a0, t_a1, t_a2 = get_intermediate_layer_tensors(prev_layer, mixed_layer)\n",
    "\n",
    "        # Define intermediate conv output tensors\n",
    "        t_inf_0 = get_infs(t_a0, t_w0)\n",
    "        t_inf_1 = get_infs(t_a1, t_w2)\n",
    "        t_inf_2 = get_infs(t_a2, t_w4)\n",
    "        t_inf_3 = get_infs(t_a0, t_w5)\n",
    "        t_inf_4 = get_infs(t_a0, t_w1)\n",
    "        t_inf_5 = get_infs(t_a0, t_w3)\n",
    "\n",
    "        # Run with batch\n",
    "        progress_counter = 0\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            tic = time()\n",
    "\n",
    "            try:\n",
    "                with tqdm.tqdm(total=1281167, unit='imgs') as pbar:\n",
    "\n",
    "                    while(True):\n",
    "                        progress_counter += 1\n",
    "\n",
    "                        # Run the session\n",
    "                        if is_mixed:\n",
    "                            labels, inf_0, inf_1, inf_2, inf_3 = sess.run([t_labels, t_inf_0, t_inf_1, t_inf_2, t_inf_3])\n",
    "\n",
    "                        elif branch == 1:\n",
    "                            labels, inf_4 = sess.run([t_labels, t_inf_4])\n",
    "\n",
    "                        elif branch == 2:\n",
    "                            labels, inf_5 = sess.run([t_labels, t_inf_5])\n",
    "\n",
    "                        # Add up the counts\n",
    "                        if is_mixed:\n",
    "                            channel = 0\n",
    "                            for frag, inf in enumerate([inf_0, inf_1, inf_2, inf_3]):\n",
    "                                channel = update_I(layer, inf, channel, I_layer, labels, frag_sz[frag], k, outlier_nodes_idx)\n",
    "\n",
    "                        elif branch == 1:\n",
    "                            update_I(layer, inf_4, 0, I_layer, labels, frag_sz[4], k, outlier_nodes_idx)\n",
    "\n",
    "                        elif branch == 2:\n",
    "                            update_I(layer, inf_5, 0, I_layer, labels, frag_sz[5], k, outlier_nodes_idx)\n",
    "\n",
    "                        pbar.update(len(labels))\n",
    "                        # print(inf_0.shape, inf_1.shape, inf_2.shape, inf_3.shape, inf_4.shape, inf_5.shape)\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "\n",
    "            # Save I_layer\n",
    "            with open(I_mat_dirpath + 'I_%s.json' % layer, 'w') as f:\n",
    "                json.dump(I_layer, f, indent=2)\n",
    "\n",
    "            end = time.time()\n",
    "            print(end - start)\n",
    "            print(progress_counter)\n",
    "            print(progress_counter * batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
