{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate graph for multiple benign and attacked imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "# Set auto reload for python functions\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Helper libraries\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.readwrite import json_graph\n",
    "\n",
    "# GoogLeNet\n",
    "import lucid.modelzoo.vision_models as models\n",
    "\n",
    "# Libraries provided by Massif project\n",
    "import constant\n",
    "import A_matrix\n",
    "import I_matrix\n",
    "import model_helper\n",
    "import gen_graph\n",
    "\n",
    "print(tf.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import GoogLeNet (InceptionV1) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet = models.InceptionV1()\n",
    "googlenet.load_graphdef()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constants and hyperparameters in args:\n",
      "['gpu', 'batch_A', 'batch_I', 'layer', 'k_A', 'layer_sizes', 'layers', 'layer_blk_sizes', 'blk_headers', 'num_classes', 'img_width', 'img_height']\n"
     ]
    }
   ],
   "source": [
    "args = constant.Args\n",
    "arg_keys = [arg for arg in args.__dict__.keys() if '__' not in arg]\n",
    "\n",
    "print('Constants and hyperparameters in args:')\n",
    "print(arg_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read benign images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_dirpath = '../data/sample-images/sample-benign'\n",
    "correct_classname = 'giant_panda'\n",
    "\n",
    "benign_imgs = []\n",
    "for benign_filename in os.listdir(benign_dirpath):\n",
    "    if 'jpg' in benign_filename:\n",
    "        benign_img = plt.imread('{}/{}'.format(benign_dirpath, benign_filename))\n",
    "        benign_imgs.append(benign_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read attacked images with different strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epss = [0.5, 1, 1.5, 2, 2.5, 3, 3.5]\n",
    "attacked_imgs = {eps: [] for eps in epss}\n",
    "\n",
    "for eps in epss:\n",
    "    attacked_dirpath = '../data/sample-images/attacked-{}'.format(eps)\n",
    "    for attacked_filename in os.listdir(attacked_dirpath):        \n",
    "        if 'npy' in attacked_filename:\n",
    "            img = np.load('{}/{}'.format(attacked_dirpath, attacked_filename))\n",
    "            attacked_imgs[eps].append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A_matrix: generate nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A_matrix of the **benign** images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize A-matrix\n",
    "A_benign = A_matrix.init_A_matrix_single_class(args)\n",
    "\n",
    "# Get activation score of all neurons in all layers for all images\n",
    "act_scores_benign = model_helper.get_all_layers_activation_score(googlenet, benign_imgs, args.layers)\n",
    "\n",
    "# Generate A-matrix based on the activatin score\n",
    "for layer in args.layers:\n",
    "    median_act_score_across_imgs = np.median(act_scores_benign[layer], axis=0)\n",
    "    A_benign[layer] = median_act_score_across_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get string converted A-matrix to save it into json file\n",
    "str_A_benign = {layer: A_benign[layer].astype(str).tolist() for layer in args.layers}\n",
    "\n",
    "# Save the string converted A-matrix into json file\n",
    "targeted_classname = 'armadillo'\n",
    "A_matrix_benign_dirpath = '/Users/haekyu/data/massif/A-mat/aggregated/benign'\n",
    "filename = '{}/A-benign-{}-{}.json'.format(A_matrix_benign_dirpath, correct_classname, targeted_classname)\n",
    "with open (filename, 'w') as f:\n",
    "    json.dump(str_A_benign, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A_matrix of the **attacked** image with different strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_attacked_dict = {}\n",
    "for eps in epss:\n",
    "    A_attacked = A_matrix.init_A_matrix_single_class(args)\n",
    "    A_attacked_dict[eps] = A_attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate A-matrix for atttacked images with different eps\n",
    "for eps in epss:\n",
    "    \n",
    "    # Get the activation scores\n",
    "    act_scores_attacked = model_helper.get_all_layers_activation_score(googlenet, attacked_imgs[eps], args.layers)\n",
    "    \n",
    "    # Save the median activation scores\n",
    "    for layer in args.layers:\n",
    "        median_act_score_across_imgs = np.median(act_scores_attacked[layer], axis=0)\n",
    "        A_attacked_dict[eps][layer] = median_act_score_across_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get string converted A-matrix to save it into json file\n",
    "str_A_attacked_dict = {eps: {layer: A_attacked_dict[eps][layer].astype(str).tolist() for layer in args.layers} for eps in epss}\n",
    "\n",
    "# Save the string converted A-matrix\n",
    "A_matrix_attacked_dirpath = '/Users/haekyu/data/massif/A-mat/aggregated/attacked'\n",
    "for eps in epss:\n",
    "    filename = '{}/A-attacked-{}-{}-{}.json'.format(A_matrix_attacked_dirpath, correct_classname, targeted_classname, eps)\n",
    "    with open (filename, 'w') as f:\n",
    "        json.dump(str_A_attacked_dict[eps], f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I_matrix: generate edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I_matrix of the **benign** images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/haekyu/GoogleDrive/Gatech/massif/code/I_matrix.py:122: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/haekyu/GoogleDrive/Gatech/massif/code/I_matrix.py:122: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate I matrix for benign images\n",
    "I_benign = I_matrix.gen_aggregated_I_matrix(args, benign_imgs, googlenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert I matrix into string to save the matrix into json file\n",
    "blks = list(I_benign.keys())\n",
    "str_I_benign = {blk: I_benign[blk].astype(str).tolist() for blk in blks}\n",
    "\n",
    "# Save the string converted I-matrix into json file\n",
    "I_matrix_benign_dirpath = '/Users/haekyu/data/massif/I-mat/aggregated/benign'\n",
    "filename = '{}/I-benign-{}-{}.json'.format(I_matrix_benign_dirpath, correct_classname, targeted_classname)\n",
    "with open (filename, 'w') as f:\n",
    "    json.dump(str_I_benign, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I_matrix of the **attacked** images with different strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Is_attacked = {}\n",
    "for eps in epss:\n",
    "    I_attacked = I_matrix.gen_aggregated_I_matrix(args, attacked_imgs[eps], googlenet)\n",
    "    Is_attacked[eps] = I_attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save I matrix for attacked images with different eps\n",
    "I_matrix_attacked_dirpath = '/Users/haekyu/data/massif/I-mat/aggregated/attacked'\n",
    "\n",
    "for eps in epss:\n",
    "    filename = '{}/I-attacked-{}-{}-{}.json'.format(I_matrix_attacked_dirpath, correct_classname, targeted_classname, eps)\n",
    "\n",
    "    # Convert I matrix into string\n",
    "    str_I_attacked = {blk: Is_attacked[eps][blk].astype(str).tolist() for blk in blks}\n",
    "    \n",
    "    # Save the string converted I-matrix into json file\n",
    "    with open (filename, 'w') as f:\n",
    "        json.dump(str_I_attacked, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [No Need] Generate full graph of the **Benign** images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_benign = gen_graph.gen_full_graph(args, A_benign, I_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_benign_json = json_graph.node_link_data(G_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_str_parsed_nodes = list(map(lambda x: {'weight': str(x['weight']), 'id': x['id']}, G_benign_json['nodes']))\n",
    "benign_str_parsed_links = list(map(lambda x: {'source': x['source'], 'target': x['target'], 'weight': str(x['weight'])}, G_benign_json['links']))\n",
    "G_benign_str_json = {'nodes': benign_str_parsed_nodes, 'links': benign_str_parsed_links}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir_path = '/Users/haekyu/data/massif/full-graph/aggregated'\n",
    "file_path = '{}/{}.json'.format(graph_dir_path, 'G-benign')\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(G_benign_str_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [No Need] Generate full graph of the **Attacked** images with different strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in epss:\n",
    "    G_attacked = gen_graph.gen_full_graph(args, A_attacked_dict[eps], Is_attacked[eps])\n",
    "    G_attacked_json = json_graph.node_link_data(G_attacked)\n",
    "    attacked_str_parsed_nodes = list(map(lambda x: {'weight': str(x['weight']), 'id': x['id']}, G_attacked_json['nodes']))\n",
    "    attacked_str_parsed_links = list(map(lambda x: {'source': x['source'], 'target': x['target'], 'weight': str(x['weight'])}, G_attacked_json['links']))\n",
    "    G_attacked_str_json = {'nodes': attacked_str_parsed_nodes, 'links': attacked_str_parsed_links}\n",
    "    graph_dir_path = '/Users/haekyu/data/massif/full-graph/aggregated'\n",
    "    file_path = '{}/{}-{}.json'.format(graph_dir_path, 'G-attacked', eps)\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(G_attacked_str_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the top neurons in **Benign** graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_p = 0.2\n",
    "top_neurons_benign = {}\n",
    "for layer in A_benign:\n",
    "    num = int(len(A_benign[layer]) * top_p)\n",
    "    sorted_neurons = np.argsort(-A_benign[layer])[:num]\n",
    "    top_neurons_benign[layer] = [{'neuron': str(neuron), 'weight': str(A_benign[layer][neuron])} for neuron in sorted_neurons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir_path = '/Users/haekyu/data/massif/aggregated/panda-armadillo/top-neurons'\n",
    "file_path = '{}/{}.json'.format(graph_dir_path, 'top-neurons-benign')\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(top_neurons_benign, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the top neurons in **Attacked** graph with different strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_p = 0.2\n",
    "for eps in A_attacked_dict:\n",
    "    top_neurons_attacked = {}\n",
    "    A_attacked = A_attacked_dict[eps]\n",
    "    for layer in A_attacked:\n",
    "        num = int(len(A_attacked[layer]) * top_p)\n",
    "        sorted_neurons = np.argsort(-A_attacked[layer])[:num]\n",
    "        top_neurons_attacked[layer] = [{'neuron': str(neuron), 'weight': str(A_attacked[layer][neuron])} for neuron in sorted_neurons]\n",
    "        \n",
    "    graph_dir_path = '/Users/haekyu/data/massif/aggregated/panda-armadillo/top-neurons'\n",
    "    file_path = '{}/{}-{}.json'.format(graph_dir_path, 'top-neurons-attacked', eps)\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(top_neurons_attacked, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "dlwp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
